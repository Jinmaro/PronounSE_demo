<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>PronounSE Demo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      font-family: 'Segoe UI', sans-serif;
      margin: 0;
      padding: 0;
      background: #f4f4f4;
      color: #333;
      line-height: 1.6;
      display: flex;
      justify-content: center;
    }
    .container {
      max-width: 800px;
      padding: 30px;
      background: #fff;
      margin: 40px 20px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
      border-radius: 10px;
    }
    h1 {
      font-size: 28px;
      color: #111;
      margin-bottom: 0.5em;
    }
    h2 {
      margin-top: 1.5em;
      color: #444;
    }
    p {
      margin-top: 0.5em;
    }
    .author {
        font-size: 18px;
        color: #333;
        margin-bottom: 0;
    }

    .affiliation {
        font-size: 14px;
        color: #777;
        display: block;
        margin-top: 4px;
    }

    audio {
      margin-top: 10px;
      width: 100%;
    }
    .link-button {
      display: inline-block;
      margin: 10px 10px 0 0;
      padding: 8px 14px;
      background-color: #007acc;
      color: #fff;
      text-decoration: none;
      border-radius: 5px;
    }
    .link-button:hover {
      background-color: #005f99;
    }
    .footer {
      text-align: center;
      font-size: 14px;
      margin-top: 40px;
      color: #aaa;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>PronounSE: SFX Synthesizer from Language-Independent Vocal Mimicry</h1>
    <p class="author">
        Riki Takizawa<sup>1, 4</sup>, Shigeyuki Hirai<sup>2</sup>, Asako Kanezaki<sup>3</sup>, Hitoshi Suda<sup>4</sup><br>
        <span class="affiliation">
            <sup>1</sup>Graduate School of Kyoto Sangyo University, Japan<br>
            <sup>2</sup>Kyoto Sangyo University, Japan<br>
            <sup>3</sup>Institute of Science Tokyo, Japan<br>
            <sup>4</sup>National Institute of Advanved Industrial Science and Technology, Japan
        </span>
    </p>

    <h2>Abstract</h2>
    <p>
        Recent advancements in generative methods based on diffusion processes trained on large-scale datasets have enabled the creation of high-quality visual content. Alongside this progress, there is a growing demand for technologies that can generate environmental sounds corresponding to video scenes. In this study, we propose <b>PronounSE</b>, a sound effect synthesis method that requires neither specialized production techniques nor domain-specific expertise. The method <b>relies solely on human vocal imitations of sound effects</b>. PronounSE is trained to <b>learn the correspondence between feature variations in vocal imitations and actual sound effects, thereby enabling the synthesis of sounds that reflect the nuances of vocal expressions</b>. We trained
    </p>

    <h2>Audio Demos</h2>
    <p>Reference Audio</p>
    <audio controls src="audio/reference.wav"></audio>

    <p>Generated Audio</p>
    <audio controls src="audio/generated.wav"></audio>

    <h2>Links</h2>
    <a class="link-button" href="https://github.com/Jinmaro/PronounSE" target="_blank">Pretrained Model</a>
    <a class="link-button" href="https://arxiv.org/abs/xxxx.xxxxx" target="_blank">Paper</a>

    <div class="footer">
      &copy; 2025 Riki Takizawa. All rights reserved.
    </div>
  </div>
</body>
</html>
